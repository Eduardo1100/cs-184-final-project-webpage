<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>CS184/284A Final Report | MIS + ML-guided Adaptive Sampling</title>

  <!-- Inter -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
          {left: "$", right: "$", display: false},
          {left: "\\(", right: "\\)", display: false}
        ]
      });
    });
  </script>

  <style>
    :root{
      --bg: #0b0f14;
      --panel: #0f1620;
      --panel-2: #0c121a;
      --text: #e7eef8;
      --muted: rgba(231,238,248,.72);
      --faint: rgba(231,238,248,.45);
      --border: rgba(231,238,248,.12);
      --border-2: rgba(231,238,248,.18);

      --accent: #8ab4ff;
      --accent-2: #7ee6b5;
      --warn: #ffd38a;

      --maxw: 980px;
      --radius: 16px;
      --radius-sm: 12px;

      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --shadow-soft: 0 8px 22px rgba(0,0,0,.28);

      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      --sans: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
    }

    *{ box-sizing:border-box; margin:0; padding:0; }
    html{ scroll-behavior:smooth; }
    body{
      font-family: var(--sans);
      background:
        radial-gradient(900px 600px at 15% -10%, rgba(138,180,255,.18), transparent 60%),
        radial-gradient(800px 500px at 90% 0%, rgba(126,230,181,.10), transparent 55%),
        radial-gradient(1000px 800px at 60% 110%, rgba(138,180,255,.08), transparent 55%),
        var(--bg);
      color: var(--text);
      line-height: 1.7;
      padding-bottom: 3.25rem;
    }

    .nav{
      position: sticky;
      top: 0;
      z-index: 50;
      backdrop-filter: blur(10px);
      background: rgba(11,15,20,.72);
      border-bottom: 1px solid var(--border);
    }
    .nav-inner{
      max-width: var(--maxw);
      margin: 0 auto;
      padding: .85rem 1.25rem;
      display:flex;
      align-items:center;
      justify-content:space-between;
      gap: 1rem;
    }
    .brand{ display:flex; flex-direction:column; gap:.15rem; min-width: 220px; }
    .brand .title{ font-weight: 700; letter-spacing: .2px; font-size: .98rem; color: var(--text); }
    .brand .subtitle{ font-size: .82rem; color: var(--muted); }

    .nav a{
      color: var(--muted);
      text-decoration:none;
      font-weight: 550;
      font-size: .9rem;
      padding: .35rem .55rem;
      border-radius: 10px;
      border: 1px solid transparent;
      transition: .15s ease;
      white-space: nowrap;
    }
    .nav a:hover{
      color: var(--text);
      border-color: var(--border);
      background: rgba(255,255,255,.03);
    }
    .nav-links{ display:flex; flex-wrap: wrap; justify-content:flex-end; gap: .25rem; }

    header.hero{
      max-width: var(--maxw);
      margin: 1.75rem auto 0;
      padding: 0 1.25rem;
    }
    .hero-card{
      border: 1px solid var(--border);
      border-radius: calc(var(--radius) + 2px);
      background: linear-gradient(180deg, rgba(15,22,32,.92), rgba(12,18,26,.92));
      box-shadow: var(--shadow);
      padding: 1.75rem 1.75rem 1.35rem;
      position: relative;
      overflow: hidden;
    }
    .hero-card:before{
      content:"";
      position:absolute;
      inset:-1px;
      background:
        radial-gradient(520px 260px at 15% 15%, rgba(138,180,255,.22), transparent 55%),
        radial-gradient(520px 260px at 85% 35%, rgba(126,230,181,.12), transparent 58%);
      pointer-events:none;
      opacity:.9;
    }
    .hero-grid{
      position:relative;
      display:grid;
      grid-template-columns: 1.2fr .8fr;
      gap: 1.25rem;
      align-items: start;
    }
    .hero h1{
      font-size: clamp(1.6rem, 2.2vw, 2.15rem);
      letter-spacing: -0.4px;
      line-height: 1.2;
      margin-bottom: .55rem;
    }
    .hero h1 .accent{ color: var(--accent); }
    .hero p{ color: var(--muted); font-size: 1.0rem; max-width: 70ch; }

    .meta{
      border: 1px solid var(--border);
      background: rgba(0,0,0,.18);
      border-radius: var(--radius-sm);
      padding: 1rem;
    }
    .meta .row{
      display:flex;
      justify-content:space-between;
      gap: .75rem;
      padding: .35rem 0;
      border-bottom: 1px dashed rgba(231,238,248,.12);
    }
    .meta .row:last-child{ border-bottom:none; }
    .meta .k{ color: var(--faint); font-size:.85rem; }
    .meta .v{ color: var(--text); font-size:.9rem; font-weight:600; text-align:right; }

    main{
      max-width: var(--maxw);
      margin: 1.25rem auto 0;
      padding: 0 1.25rem;
    }

    .card{
      background: rgba(15,22,32,.88);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      box-shadow: var(--shadow-soft);
      padding: 1.5rem;
      margin-top: 1.25rem;
    }

    .card h2{
      font-size: 1.35rem;
      letter-spacing: -0.2px;
      margin-bottom: .85rem;
      display:flex;
      align-items:center;
      gap: .65rem;
    }
    .card h2:before{
      content:"";
      width: 10px;
      height: 10px;
      border-radius: 999px;
      background: var(--accent);
      box-shadow: 0 0 0 4px rgba(138,180,255,.15);
      flex: 0 0 auto;
    }
    .card h3{
      margin-top: 1.05rem;
      margin-bottom: .5rem;
      font-size: 1.12rem;
      color: var(--text);
      letter-spacing: -0.15px;
    }
    .card h4{
      margin-top: .9rem;
      margin-bottom: .45rem;
      font-size: 1.0rem;
      color: var(--muted);
      font-weight: 650;
    }

    p{ margin: .65rem 0; color: var(--muted); }
    strong{ color: var(--text); }
    em{ color: rgba(231,238,248,.9); }

    ul, ol{
      padding-left: 1.15rem;
      margin: .75rem 0 1rem;
      color: var(--muted);
    }
    li{ margin: .45rem 0; }

    a{
      color: var(--accent);
      text-decoration: none;
      border-bottom: 1px solid rgba(138,180,255,.25);
    }
    a:hover{
      border-bottom-color: rgba(138,180,255,.6);
      color: #bcd2ff;
    }

    .callout{
      border: 1px solid rgba(138,180,255,.22);
      background: rgba(138,180,255,.06);
      border-radius: var(--radius-sm);
      padding: .9rem 1rem;
      color: var(--muted);
      margin: 1rem 0;
    }
    .callout strong{ color: var(--text); }
    .callout.warn{
      border-color: rgba(255,211,138,.25);
      background: rgba(255,211,138,.08);
    }
    .callout.good{
      border-color: rgba(126,230,181,.20);
      background: rgba(126,230,181,.08);
    }
    .callout .small{
      margin-top:.5rem;
      color: var(--faint);
      font-size: .95rem;
    }

    /* glossary and definition blocks */
    .glossary{
      display:grid;
      grid-template-columns: 1fr 1fr;
      gap: .9rem;
      margin-top: .85rem;
    }
    .def{
      border: 1px solid rgba(231,238,248,.12);
      background: rgba(0,0,0,.14);
      border-radius: var(--radius-sm);
      padding: .85rem .9rem;
    }
    .def .term{
      font-weight: 700;
      color: var(--text);
      margin-bottom: .35rem;
      font-size: .98rem;
      letter-spacing: -0.1px;
    }
    .def .meaning{
      color: var(--muted);
      font-size: .95rem;
    }

    code{
      font-family: var(--mono);
      font-size: .92em;
      background: rgba(0,0,0,.28);
      border: 1px solid rgba(231,238,248,.12);
      padding: .15rem .38rem;
      border-radius: 8px;
      color: rgba(126,230,181,.95);
      white-space: pre-wrap;
    }
    pre{
      margin: .85rem 0 1rem;
      padding: 1rem 1rem;
      border-radius: var(--radius-sm);
      border: 1px solid var(--border);
      background: rgba(0,0,0,.35);
      overflow:auto;
      box-shadow: inset 0 0 0 1px rgba(0,0,0,.22);
    }
    pre code{
      border: none;
      background: transparent;
      padding: 0;
      color: rgba(231,238,248,.9);
      font-size: .92rem;
    }

    .algo{
      margin-top: .6rem;
      padding: 1rem;
      border-radius: var(--radius-sm);
      border: 1px solid rgba(231,238,248,.12);
      background: rgba(0,0,0,.18);
    }
    .algo p{ margin: .45rem 0; }
    .algo ul, .algo ol{ margin: .55rem 0 .25rem; }
    .inline-note{ color: var(--faint); font-size: .95rem; }

    .grid-2{
      display:grid;
      grid-template-columns: repeat(2, minmax(0,1fr));
      gap: 1rem;
      margin-top: .85rem;
    }
    @media (max-width: 860px){
      .hero-grid{ grid-template-columns: 1fr; }
      .grid-2{ grid-template-columns: 1fr; }
      .glossary{ grid-template-columns: 1fr; }
      .brand{ min-width: unset; }
    }

    figure{
      margin:0;
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      overflow:hidden;
      background: rgba(0,0,0,.22);
    }
    figure img{
      display:block;
      width:100%;
      height:auto;
      background:#000;
    }
    figcaption{
      padding: .7rem .8rem;
      font-size: .9rem;
      color: var(--muted);
      border-top: 1px solid rgba(231,238,248,.10);
      background: rgba(0,0,0,.18);
    }

    details{
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: .85rem 1rem;
      background: rgba(0,0,0,.16);
      margin-top: .85rem;
    }
    summary{
      cursor:pointer;
      color: var(--text);
      font-weight: 650;
      list-style: none;
    }
    summary::-webkit-details-marker{ display:none; }
    summary:before{
      content:"▸";
      display:inline-block;
      margin-right:.5rem;
      color: var(--accent);
      transform: translateY(-1px);
    }
    details[open] summary:before{ content:"▾"; }

    hr.sep{
      border:0;
      border-top: 1px solid var(--border);
      margin: 1.5rem 0;
    }

    footer{
      max-width: var(--maxw);
      margin: 1.75rem auto 0;
      padding: 0 1.25rem;
      color: var(--faint);
      text-align:center;
      font-size: .92rem;
    }

    .chips{ display:flex; flex-wrap:wrap; gap:.5rem; margin-top: .9rem; }
    .chip{
      border: 1px solid rgba(231,238,248,.14);
      background: rgba(0,0,0,.16);
      padding: .35rem .55rem;
      border-radius: 999px;
      color: var(--muted);
      font-size: .85rem;
      white-space: nowrap;
    }
    .chip strong{ color: var(--text); font-weight:650; }

    section[id]{ scroll-margin-top: 82px; }
  </style>
</head>

<body>
  <!-- Sticky Nav -->
  <div class="nav">
    <div class="nav-inner">
      <div class="brand">
        <div class="title">CS184/284A Final Report</div>
        <div class="subtitle">Multiple Importance Sampling + ViT Saliency-Biased Adaptive Sampling</div>
      </div>
      <div class="nav-links">
        <a href="#overview">Overview</a>
        <a href="#glossary">Glossary</a>
        <a href="#abstract">Abstract</a>
        <a href="#technical_approach">Approach</a>
        <a href="#mis-direct-lighting">MIS</a>
        <a href="#vit-saliency-approach">SBAS</a>
        <a href="#mis_results">Results</a>
        <a href="#references">Refs</a>
        <a href="#contributions">Team</a>
      </div>
    </div>
  </div>

  <!-- Hero -->
  <header class="hero">
    <div class="hero-card">
      <div class="hero-grid">
        <div>
          <h1>
            Final Report:
            <span class="accent">Better light sampling</span>
            &amp;
            <span class="accent">smarter sample budgets</span>
          </h1>
          <p>
            This report explains how we made a path tracer produce cleaner images with fewer wasted samples.
            We did it in two complementary ways: (1) we improved <em>how</em> we choose random light directions (MIS),
            and (2) we improved <em>where</em> we spend samples in the image (SBAS using a ViT saliency prior).
          </p>

          <div class="chips">
            <div class="chip"><strong>Renderer:</strong> C++ path tracer</div>
            <div class="chip"><strong>Saliency:</strong> CLIP/ViT (PyTorch)</div>
            <div class="chip"><strong>Math:</strong> KaTeX</div>
          </div>

          <p class="callout warn" style="margin-top:1rem;">
            <strong>AI Acknowledgement.</strong>
            This report was created with assistance from <strong>ChatGPT (OpenAI)</strong> for organization, editing, and styling.
          </p>

          <p style="margin-top:.75rem;">
            <strong>Video:</strong>
            <a href="https://drive.google.com/file/d/1FmJdRotG1wfGd1_JoAG813qy7aiI03gU/view?usp=sharing" target="_blank" rel="noopener">
              Google Drive link
            </a>
            <br>
            <strong>Slides:</strong>
            <a href="https://docs.google.com/presentation/d/1e5vjsgep_5mhzLQqGijvfYpUiQ3aPC5hliOyJ_nt04g/edit?usp=sharing" target="_blank" rel="noopener">
              Google Slides link
            </a>
          </p>
        </div>

        <aside class="meta" aria-label="report metadata">
          <div class="row"><div class="k">Course</div><div class="v">CS184/284A</div></div>
          <div class="row"><div class="k">Project</div><div class="v">Final</div></div>
          <div class="row"><div class="k">What improved?</div><div class="v">Variance</div></div>
          <div class="row"><div class="k">Scenes</div><div class="v">CBspheres_tex, CBdragon_microfacet_au</div></div>
          <div class="row"><div class="k">Target spp</div><div class="v">4096</div></div>
        </aside>
      </div>
    </div>
  </header>

  <main>
    <!-- NEW: Overview (non-expert friendly) -->
    <section id="overview" class="card">
      <h2>Overview</h2>

      <p>
        A <strong>path tracer</strong> renders an image by simulating many random light paths.
        For each pixel, it repeatedly shoots a ray into the scene, lets it bounce off surfaces,
        and adds up the light that eventually reaches the camera.
      </p>

      <p class="callout good">
        <strong>Main problem:</strong> randomness creates noise.
        If we spend samples in the “wrong places” (directions that miss lights, or pixels that don’t need more work),
        the image converges slowly.
        <div class="small">
          Our goal is not to remove randomness. The goal is to make randomness <em>efficient</em>, so each sample has a higher chance of contributing meaningful light.
        </div>
      </p>

      <h3>What we added (in one sentence each)</h3>
      <ul>
        <li><strong>Advanced materials (BSDFs):</strong> we added realistic mirror, glass, and microfacet metal behavior, so the scene can create sharp reflections, refractions, and glossy highlights.</li>
        <li><strong>MIS for direct lighting:</strong> when estimating light at a surface point, we combine two “proposal strategies” for choosing an incoming direction: sample the light directly and sample the BSDF.</li>
        <li><strong>SBAS (saliency-biased adaptive sampling):</strong> we allocate more samples to visually important pixels using a ViT/CLIP saliency map, while still using variance-based stopping so we do not over-trust the prior.</li>
      </ul>

      <p class="callout">
        <strong>How to read this page:</strong> If you’re new to rendering, read the Glossary next.
        If you already know the basics, jump to MIS (the math-heavy part) and then SBAS (the system design part).
      </p>
    </section>

    <!-- NEW: Glossary / definitions -->
    <section id="glossary" class="card">
      <h2>Glossary (quick definitions)</h2>
      <p>
        These are the minimum concepts you need to follow the rest of the report.
        We keep the explanations informal here, then use rigorous equations in later sections.
      </p>

      <div class="glossary">
        <div class="def">
          <div class="term">Radiance \(L\)</div>
          <div class="meaning">
            “How much light” travels in a specific direction. Path tracing estimates radiance arriving at the camera.
          </div>
        </div>

        <div class="def">
          <div class="term">BSDF \(f(\omega_o,\omega_i)\)</div>
          <div class="meaning">
            A function that tells you how a surface scatters light: given incoming direction \(\omega_i\), how much is sent toward outgoing direction \(\omega_o\).
          </div>
        </div>

        <div class="def">
          <div class="term">PDF \(p(\omega)\)</div>
          <div class="meaning">
            The probability density of sampling direction \(\omega\). Monte Carlo estimators divide by the PDF to stay unbiased.
          </div>
        </div>

        <div class="def">
          <div class="term">Variance (noise)</div>
          <div class="meaning">
            Even if an estimator is correct on average, random samples fluctuate. High variance shows up as grainy noise and “fireflies”.
          </div>
        </div>

        <div class="def">
          <div class="term">Delta BSDF</div>
          <div class="meaning">
            A “perfectly sharp” distribution (mirror/glass specular). It only scatters into one exact direction, so most random proposals miss it.
          </div>
        </div>

        <div class="def">
          <div class="term">MIS</div>
          <div class="meaning">
            Multiple Importance Sampling. Combine multiple ways of sampling the same integral, weighting each sample using its PDF to reduce variance.
          </div>
        </div>

        <div class="def">
          <div class="term">Adaptive sampling</div>
          <div class="meaning">
            Stop sampling pixels that have already converged (low uncertainty), and spend more samples on pixels that still look noisy.
          </div>
        </div>

        <div class="def">
          <div class="term">Saliency map</div>
          <div class="meaning">
            A per-pixel heatmap predicting which regions are visually important. We use a ViT (CLIP) to compute it.
          </div>
        </div>
      </div>

      <p class="callout">
        <strong>Technical note.</strong> We keep the estimators unbiased by always dividing by the correct PDF.
        The “smarts” (MIS/SBAS) are about choosing better PDFs and allocating compute, not changing the physics.
      </p>
    </section>

    <section id="abstract" class="card">
      <h2>Abstract</h2>
      <p>
        We extended our HW3 path tracer with three additions that together reduce noise and wasted computation:
      </p>
      <ol>
        <li>
          <strong>Advanced BSDFs.</strong>
          Mirror and glass introduce perfectly sharp reflection/refraction, while microfacet metal produces realistic glossy highlights.
        </li>
        <li>
          <strong>MIS for direct lighting.</strong>
          We estimate the direct illumination at a surface point by combining (a) explicitly sampling light sources and
          (b) sampling the BSDF. We blend them using the two-sample power heuristic (\(\beta=2\)) and add a delta-aware tweak for specular surfaces.
        </li>
        <li>
          <strong>SBAS (ViT saliency-biased adaptive sampling).</strong>
          We compute a CLIP/ViT saliency heatmap and use it to bias per-pixel sample budgets and convergence thresholds,
          while still relying on variance-based confidence intervals to prevent the prior from causing harm when it is wrong.
        </li>
      </ol>

      <p class="callout">
        <strong>High-level takeaway:</strong> MIS reduces variance by sampling <em>better directions</em>.
        SBAS reduces wasted work by sampling <em>better pixels</em>.
      </p>
    </section>

    <section id="technical_approach" class="card">
      <h2>1. Technical Approach</h2>

      <h3>1.1 Advanced BSDFs (materials)</h3>
      <p>
        A BSDF is the mathematical rule that tells the renderer how light changes direction at a surface.
        If the BSDF is wrong, the image will look wrong, and the sampling strategy will also struggle.
      </p>

      <ul>
        <li>
          <strong>Mirror BSDF (delta reflection)</strong>
          <div class="algo">
            <p><strong>What it models.</strong> A perfect mirror reflects light into exactly one direction.</p>
            <p>
              <strong>Mathematical behavior.</strong> The BSDF is a <em>delta distribution</em>:
              it is zero everywhere except at the perfect reflection direction.
            </p>
            <p>
              <strong>Sampling.</strong> Deterministic:
              \( \omega_i = \mathrm{reflect}(\omega_o) \) and we set <code>pdf = 1</code> because we always return that one direction.
            </p>
            <p class="inline-note">
              Why “tolerance”? In floating-point arithmetic, “exact equality” is fragile.
              We treat directions within ~\(10^{-3}\) as “the same” to avoid false zeros.
            </p>
          </div>
        </li>

        <li>
          <strong>Glass BSDF (specular reflection + refraction with Fresnel)</strong>
          <div class="algo">
            <p><strong>What it models.</strong> Glass does two things: it reflects some light and transmits the rest.</p>

            <p>
              <strong>How we decide the split.</strong>
              Fresnel gives a reflection probability \(F\) that depends on angle and indices of refraction.
              At grazing angles, glass reflects more; at normal incidence, it transmits more.
              Total internal reflection (TIR) is handled by setting \(F=1\).
            </p>

            <p>
              <strong>Sampling strategy.</strong> We flip a biased coin:
            </p>
            <ul>
              <li>With probability \(F\): sample the reflection direction.</li>
              <li>With probability \(1-F\): sample the refraction direction from Snell’s law.</li>
            </ul>

            <p>
              <strong>Energy correction.</strong>
              Transmitted radiance scales by \((\eta_i/\eta_t)^2\) to account for how radiance transforms across media.
              We also divide by \(|\cos\theta_t|\) when needed so the estimator matches the rendering equation’s geometry factor.
            </p>

            <p class="inline-note">
              This section is where bugs often appear. A common mistake is clamping \(\cos\theta\) to \(\max(0,\cos\theta)\),
              which breaks transmission because refracted rays live on the “other side” of the surface.
            </p>
          </div>
        </li>

        <li>
          <strong>Microfacet conductor (metal) with Beckmann NDF</strong>
          <div class="algo">
            <p>
              <strong>What it models.</strong> Metals look glossy because they behave like a collection of tiny mirror-like facets.
              A microfacet model makes that idea precise.
            </p>

            <p>
              <strong>Rigorous model.</strong> For valid directions (\(\omega_o\!\cdot n&gt;0\) and \(\omega_i\!\cdot n&gt;0\)):
              $$f(\omega_o,\omega_i)=\frac{D(\mathbf{h})\,F(\omega_i\!\cdot\!\mathbf{h})\,G(\omega_o,\omega_i)}{4\,\cos\theta_i\,\cos\theta_o}.$$
              Here \(D\) is the Beckmann normal distribution function (controls roughness), \(F\) is the conductor Fresnel (with \((\eta,k)\)),
              and \(G\) accounts for masking/shadowing between facets.
            </p>

            <p>
              <strong>Sampling.</strong> We sample a half-vector \(\mathbf{h}\) from \(D\),
              then reflect \(\omega_o\) around \(\mathbf{h}\) to get \(\omega_i\).
              The PDF must include the Jacobian factor \(1/(4\,\omega_o\!\cdot\!\mathbf{h})\) so the estimator stays correct.
            </p>
          </div>
        </li>
      </ul>

      <hr class="sep">

      <section id="mis-direct-lighting">
        <h3>1.2 Multiple Importance Sampling (MIS) for direct lighting</h3>

        <p>
          At a surface point, “direct lighting” means: how much light arrives from light sources without extra bounces.
          Computing this is an integral over all incoming directions.
          In Monte Carlo, we approximate that integral by sampling directions.
        </p>

        <p class="callout">
          <strong>Core idea:</strong> different sampling methods are good in different situations.
          Light sampling is great when the light is small or bright, because it aims directly at lights.
          BSDF sampling is great when the surface is glossy/specular, because it aims along directions the material prefers.
          MIS blends them to reduce noise.
        </p>

        <h4>The quantity we are estimating</h4>
        <p>
          The direct lighting term at point \(\mathbf{x}\) for outgoing direction \(\omega_o\) is (conceptually):
          $$L_{\text{dir}}(\mathbf{x},\omega_o) = \int_{\Omega} f(\omega_o,\omega_i)\,L_i(\omega_i)\,|\cos\theta_i|\,d\omega_i.$$
          Where:
        </p>
        <ul>
          <li>\(f(\omega_o,\omega_i)\) is the BSDF (surface scattering).</li>
          <li>\(L_i(\omega_i)\) is incoming light from direction \(\omega_i\) (zero if blocked).</li>
          <li>\(|\cos\theta_i|\) is the geometry factor (how “head-on” the incoming direction hits the surface).</li>
        </ul>

        <h4>Estimator 1: sample the light</h4>
        <p>
          We ask the light source: “give me a direction that actually points to you.”
          The light provides a direction \(\omega_i\) with a known PDF \(p_{\text{light}}(\omega_i)\).
          Then one unbiased sample contribution is:
          $$\widehat L_{\text{light}}=\frac{f(\omega_o,\omega_i)\,L_i(\omega_i)\,|\cos\theta_i|}{p_{\text{light}}(\omega_i)}.$$
        </p>

        <h4>Estimator 2: sample the BSDF</h4>
        <p>
          We ask the surface: “give me a direction you like to scatter light.”
          The BSDF sampler returns \(\omega_i\) with PDF \(p_{\text{bsdf}}(\omega_i)\).
          If that ray hits an emissive object, we accumulate:
          $$\widehat L_{\text{bsdf}}=\frac{f(\omega_o,\omega_i)\,L_i(\omega_i)\,|\cos\theta_i|}{p_{\text{bsdf}}(\omega_i)}.$$
        </p>

        <h4>How MIS combines them (power heuristic)</h4>
        <p>
          We compute weights from the two PDFs (bigger PDF means “this strategy was more responsible for producing this direction”):
          $$w_{\text{light}}=\frac{p_{\text{light}}^2}{p_{\text{light}}^2+p_{\text{bsdf}}^2},\qquad
          w_{\text{bsdf}}=\frac{p_{\text{bsdf}}^2}{p_{\text{light}}^2+p_{\text{bsdf}}^2}.$$
        </p>
        <p>
          Then:
          $$L_{\text{dir}} \approx w_{\text{light}}\ \widehat L_{\text{light}} + w_{\text{bsdf}}\ \widehat L_{\text{bsdf}}.$$
        </p>

        <p class="callout">
          <strong>Why squaring?</strong>
          Squaring (the “power heuristic”) more aggressively favors the strategy with the higher PDF.
          In practice, that reduces variance in cases where one method is clearly better.
        </p>

        <h4>Delta-aware adjustment (why we treat mirrors/glass specially)</h4>
        <p>
          Mirror and glass have delta lobes: the “correct” incoming direction is essentially one exact direction.
          Light sampling almost never proposes that exact direction, so its contribution can become a rare-event with huge weight (fireflies).
          We therefore bias the blend toward BSDF sampling on delta BSDF surfaces:
        </p>
        <pre><code class="language-cpp">// For delta-distribution materials, adjust MIS weights to improve reflection results
if (isect.bsdf-&gt;is_delta()) {
  double weight_bsdf = 0.8;
  double weight_light = 0.2;
  return L_out_lighting_sample * weight_light + L_out_bsdf_sample * weight_bsdf;
}</code></pre>
        <p class="inline-note">
          This is a variance-reduction hack: it reduces bright outliers. It can introduce slight bias, but visually it stabilizes specular highlights.
        </p>
      </section>

      <hr class="sep">

      <section id="vit-saliency-approach">
        <h3>1.3 SBAS: ViT saliency-biased adaptive sampling</h3>
        <p>
          Adaptive sampling uses statistics: for each pixel, we track the running mean and variance of sample values.
          If the uncertainty is small enough, we stop sampling that pixel.
        </p>

        <p class="callout">
          <strong>SBAS changes only one thing:</strong> before adaptive sampling kicks in, we give some pixels a head start by allocating them more samples,
          based on a saliency map \(s(x,y)\in[0,1]\).
          We still use confidence intervals to decide when a pixel is “done”, so the algorithm can recover if the saliency prior is wrong.
        </p>

        <ul>
          <li><strong>Prior.</strong> A ViT/CLIP saliency map \(s(x,y)\) predicts which pixels are perceptually important.</li>
          <li><strong>Budget map.</strong> We map \(s\) to a per-pixel sample cap:
            \( n_{\max}(x,y)=\mathrm{clamp}(\text{base\_spp}\cdot[a+b\,s],\,n_{\min},\,n_{\max}) \).
          </li>
          <li><strong>Convergence rule.</strong> We test whether the confidence-interval half-width \(I\) is small compared to the mean \(\mu\):
            \( I \le \tau(s)\mu \), where high-saliency pixels use a smaller tolerance.
          </li>
          <li><strong>Safety rails.</strong> Clamp SPP with a hard floor/ceiling, and always allow early-stop if CI is already tight.</li>
        </ul>

        <pre><code class="language-cpp">// Policy sketch (pseudo)
int budget_from_prior = lerp(min_spp, max_spp, s);

// Anneal prior influence over time: variance gets more say later
budget_from_prior = mix(budget_from_prior, ns_aa, anneal_factor);

// CI gating: stop sampling once uncertainty is low
while (n &lt; budget_from_prior) {
  take_batch();
  if (n &gt;= 2 &amp;&amp; I &lt;= tol * mu) break;
}</code></pre>

        <p class="inline-note">
          The key design principle is “the prior proposes, the statistics decide.”
        </p>
      </section>

      <hr class="sep">

      <h3>2. Challenges (what broke and how we fixed it)</h3>

      <h4>Challenge 1: Glass BSDF bugs (black patches)</h4>
      <p>
        <strong>Issue.</strong> Early glass produced black spots and incorrect shadows.
        <strong>Cause.</strong> Some code used <code>max(0,z)</code> for the cosine term, which incorrectly zeroed transmission.
        <strong>Fix.</strong> Use \(|\cos\theta|\) for transmission paths (and ensure Fresnel/TIR logic is consistent).
      </p>

      <h4>Challenge 2: Fireflies with delta BSDFs under MIS</h4>
      <p>
        Rare-event weighting caused bright outliers. We added a delta-aware weight that favors BSDF sampling on mirror/glass.
      </p>

      <h4>Challenge 3: Saliency is imperfect</h4>
      <p>
        We prevented saliency mistakes from hurting results by clamping budgets, annealing prior influence, and CI gating.
      </p>
    </section>

    <section id="mis_results" class="card">
      <h2>3. Results</h2>
      <p>
        Below are qualitative comparisons showing how adding advanced materials and MIS/adaptive sampling improves realism and reduces noise.
      </p>

      <div class="grid-2">
        <figure>
          <img src="dragon_step1.png" alt="dragon_step_1">
          <figcaption>CBdragon: before Microfacet BSDF (missing metallic highlights).</figcaption>
        </figure>

        <figure>
          <img src="sphere_step1.png" alt="spheres_step_1">
          <figcaption>CBspheres: before advanced BSDFs (missing correct reflection/refraction behavior).</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="dragon_step2.png" alt="dragon_step_2">
          <figcaption>Microfacet added (better metal), without MIS+adaptive sampling.</figcaption>
        </figure>

        <figure>
          <img src="dragon_step3.png" alt="dragon_step_3">
          <figcaption>Microfacet + MIS + adaptive sampling (cleaner highlights, fewer noisy outliers).</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="glass_spheres_step2.png" alt="glass_spheres_step_2">
          <figcaption>Glass BSDF without MIS+adaptive sampling (more variance in caustics / specular regions).</figcaption>
        </figure>

        <figure>
          <img src="glass_spheres_step3.png" alt="glass_spheres_step_3">
          <figcaption>Glass + MIS + adaptive sampling (more stable specular lighting).</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="spheres_step2.png" alt="microfacet_spheres_step_2">
          <figcaption>Microfacet spheres without MIS+adaptive sampling.</figcaption>
        </figure>

        <figure>
          <img src="spheres_step3.png" alt="microfacet_spheres_step_3">
          <figcaption>Microfacet spheres with MIS+adaptive sampling.</figcaption>
        </figure>
      </div>
    </section>

    <section id="sbas_results" class="card">
      <h2>Saliency-Biased Adaptive Sampling (SBAS) — 4096 spp Results</h2>
      <p>
        Here we compare baseline adaptive sampling (with MIS) vs SBAS.
        SBAS uses a saliency map to bias where samples go, but still stops pixels based on confidence intervals.
        We include ~40 seconds of overhead for generating saliency from a quick 2spp preview.
      </p>

      <h3>CBdragon — Gold Microfacet Dragon (4096 spp)</h3>
      <p class="inline-note">
        The dragon’s face and spines contain high-frequency geometry and strong specular highlights.
        SBAS concentrates samples there, and reduces samples on flat background walls.
      </p>

      <div class="grid-2">
        <figure>
          <img src="CBdragon_4096spp.png" alt="CBdragon baseline 4096spp">
          <figcaption>Baseline (adaptive + MIS)</figcaption>
        </figure>
        <figure>
          <img src="CBdragon_4096spp_rate.png" alt="CBdragon baseline sampling rate">
          <figcaption>Baseline sampling rate (where the renderer spent samples)</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="CBdragon_SBAS_4096spp.png" alt="CBdragon SBAS 4096spp">
          <figcaption>SBAS (ViT-guided)</figcaption>
        </figure>
        <figure>
          <img src="CBdragon_SBAS_4096spp_rate.png" alt="CBdragon SBAS sampling rate">
          <figcaption>SBAS sampling rate (more weight on salient structure)</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="CBdragon_saliency_map.png" alt="CBdragon saliency map">
          <figcaption>Saliency map (continuous heatmap)</figcaption>
        </figure>
        <figure>
          <img src="CBdragon_saliency_mask.png" alt="CBdragon saliency mask">
          <figcaption>Saliency mask (thresholded / used to bias budgets)</figcaption>
        </figure>
      </div>

      <details>
        <summary>Timing &amp; quality</summary>
        <ul style="margin-top:.75rem;">
          <li><strong>Baseline time (4096 spp):</strong> <code>3693.3846</code> s</li>
          <li><strong>SBAS time (4096 spp):</strong> <code>2197.6018 + 40</code> s &nbsp;(<code>165.06%</code> speed-up)</li>
          <li><strong>Interpretation:</strong> We reached a similar visual quality sooner by not oversampling low-detail walls.</li>
        </ul>
      </details>

      <hr class="sep">

      <h3>CBspheres — Glass &amp; Metal Spheres (4096 spp)</h3>
      <p class="inline-note">
        In this scene, the hard parts are specular highlights and caustic-like lighting near the spheres.
        SBAS increases attention around the spheres and reduces sampling on uniform planar walls.
      </p>

      <div class="grid-2">
        <figure>
          <img src="CBspheres_4096spp.png" alt="CBspheres baseline 4096spp">
          <figcaption>Baseline (adaptive + MIS)</figcaption>
        </figure>
        <figure>
          <img src="CBspheres_4096spp_rate.png" alt="CBspheres baseline sampling rate">
          <figcaption>Baseline sampling rate</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="CBspheres_SBAS_4096spp.png" alt="CBspheres SBAS 4096spp">
          <figcaption>SBAS (ViT-guided)</figcaption>
        </figure>
        <figure>
          <img src="CBspheres_SBAS_4096spp_rate.png" alt="CBspheres SBAS sampling rate">
          <figcaption>SBAS sampling rate</figcaption>
        </figure>
      </div>

      <div class="grid-2">
        <figure>
          <img src="CBspheres_tex_saliency.png" alt="CBspheres saliency map">
          <figcaption>Saliency map</figcaption>
        </figure>
        <figure>
          <img src="CBspheres_tex_saliency_mask.png" alt="CBspheres saliency mask">
          <figcaption>Saliency mask</figcaption>
        </figure>
      </div>

      <details>
        <summary>Timing &amp; quality</summary>
        <ul style="margin-top:.75rem;">
          <li><strong>Baseline time (4096 spp):</strong> <code>1122.1510</code> s</li>
          <li><strong>SBAS time (4096 spp):</strong> <code>443.9791 + 40</code> s &nbsp;(<code>231.86%</code> speed-up)</li>
          <li><strong>Interpretation:</strong> Most pixels converge early (walls), so SBAS avoids oversampling them and spends compute on the spheres.</li>
        </ul>
      </details>
    </section>

    <section id="references" class="card">
      <h2>4. References</h2>
      <ul>
        <li>
          <a href="https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Importance_Sampling" target="_blank" rel="noopener">
            PBRT: Importance Sampling and MIS
          </a>
        </li>
        <li>
          <a href="https://graphicyan.github.io/2021/04/17/Importance-Sampling/" target="_blank" rel="noopener">
            MIS blog (Chinese)
          </a>
        </li>
        <li>
          <a href="https://openai.com/research/clip" target="_blank" rel="noopener">
            CLIP (for saliency)
          </a>
        </li>
      </ul>
      <p><strong>Tools &amp; Frameworks:</strong></p>
      <ul>
        <li>C++ for path tracer extensions</li>
        <li>PyTorch / OpenCV for saliency maps</li>
        <li>HTML/CSS + KaTeX for this report</li>
      </ul>
    </section>

    <section id="contributions" class="card">
      <h2>5. Team-member Contributions (alphabetical)</h2>
      <ul>
        <li><strong>Eduardo Cortes:</strong> Led development of the ML-guided adaptive sampling implementation / write-up.</li>
        <li><strong>Henry Michaelson:</strong> Initial (buggy) implementation of advanced BSDFs / MIS; structure and templates.</li>
        <li><strong>Yuhe Qin:</strong> Fixed BSDF implementations for glass; added assets; debugging.</li>
        <li><strong>Zhehao Yang:</strong> Fixed mirror &amp; microfacet BSDFs and MIS bugs.</li>
      </ul>

      <p class="callout">
        <strong>Quick summary of contributions:</strong> materials (BSDFs) make the physics richer, MIS reduces noise by sampling better directions,
        and SBAS reduces wasted compute by sampling better pixels.
      </p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 CS184/284A, UC Berkeley</p>
    <p style="margin-top:.35rem;">Single-file static page. Typeset with KaTeX.</p>
  </footer>
</body>
</html>
